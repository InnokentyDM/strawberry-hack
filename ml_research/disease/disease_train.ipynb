{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных\n",
    "\n",
    "Перед началом надо скачать датасет с болезнями клубники отсюда:\n",
    "https://www.kaggle.com/usmanafzaal/strawberry-disease-detection-dataset\n",
    "\n",
    "Положить папку `train` и распаковать следующей командой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqcVTmy1o4da"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmEqps8gNjCS",
    "outputId": "4967cdef-a88e-4dbf-ad3d-7baeedcd2377"
   },
   "outputs": [],
   "source": [
    "data_dir = './train'\n",
    "def load_split_train_test(datadir, valid_size = .2, batch_size=32):\n",
    "    # для тренировочного набора делаем аугментацию данных\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1),\n",
    "        transforms.RandomAffine(degrees=(-30, 30),\n",
    "                                translate=(0.2, 0.2),\n",
    "                                scale=(0.8, 1.5),\n",
    "                                shear=(-15, 15),\n",
    "                                fill=(int(0.485 * 255), \n",
    "                                      int(0.456 * 255), \n",
    "                                      int(0.406 * 255))),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomPerspective(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "    # для тестового набора просто масштабируем и нормируем\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
    "    # открываем датасет\n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir,\n",
    "                    transform=test_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    \n",
    "    # делим на train и test для проверки качества\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    # загрузка датасета\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=batch_size, num_workers=6)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=batch_size, num_workers=6)\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "trainloader, testloader = load_split_train_test(data_dir, .2)\n",
    "print(trainloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# смотрим на стандартные метрики классификации\n",
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    pred = np.array(pred > threshold, dtype=float)\n",
    "    return {'micro/precision': precision_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'micro/recall': recall_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro'),\n",
    "            'macro/precision': precision_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'macro/recall': recall_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro'),\n",
    "            }\n",
    "\n",
    "\n",
    "# мультиклассовые метрики\n",
    "def calculate_metrics_multiclass(pred, target, threshold=0.5):\n",
    "    metrics_dict = {}\n",
    "    for i in range(pred.shape[1]):\n",
    "        metrics_dict[trainloader.dataset.classes[i]] = calculate_metrics(pred[:, i], target[:, i], threshold)\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_save(model, optimizer, save_path, epoch):\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }, save_path)\n",
    "\n",
    "def checkpoint_load(model, optimizer, load_path):\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print('Loaded')\n",
    "    \n",
    "    \n",
    "os.makedirs('checkpoints/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rUJYgzOOXGk"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартная модель с замененным классификатором в конце:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9o5o22QSN0Y9",
    "outputId": "5c08e8bb-7529-4214-c7bf-c2fef17c7ade"
   },
   "outputs": [],
   "source": [
    "class Resnext50(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        resnet = models.resnext50_32x4d(pretrained=True)\n",
    "        resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "    \n",
    "# Initialize the model\n",
    "model = Resnext50(len(trainloader.dataset.classes))\n",
    "\n",
    "# Switch model to the training mode\n",
    "model.train()\n",
    "model.to(device)\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "po23dk0ZN00r"
   },
   "outputs": [],
   "source": [
    "max_epoch_number = 64\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "X1ddJ8GvN9V3",
    "outputId": "9366b54e-d5ce-496d-8a22-67d31dd2222b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "iteration = 0\n",
    "test_freq = 16\n",
    "save_freq = 16\n",
    "\n",
    "for epoch in tqdm(range(max_epoch_number)):\n",
    "    batch_losses = []\n",
    "    model.train()\n",
    "    for imgs, targets in tqdm(trainloader, leave=False):\n",
    "        imgs, target_labels = imgs.to(device), targets.to(device)\n",
    "        targets = torch.nn.functional.one_hot(target_labels, num_classes=7)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_result = model(imgs)\n",
    "        loss = criterion(model_result, targets.float())\n",
    "\n",
    "        batch_loss_value = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_losses.append(batch_loss_value)\n",
    "        \n",
    "    if epoch % test_freq == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            model_result = []\n",
    "            targets = []\n",
    "            for imgs, batch_targets in tqdm(testloader, leave=False):\n",
    "                imgs = imgs.to(device)\n",
    "                batch_targets = torch.nn.functional.one_hot(batch_targets, num_classes=7)\n",
    "                model_batch_result = model(imgs)\n",
    "                model_batch_result = torch.sigmoid(model_batch_result)\n",
    "                \n",
    "                model_result.append(model_batch_result.cpu().numpy())\n",
    "                targets.append(batch_targets.cpu().numpy())\n",
    "        model_result = np.concatenate(model_result)\n",
    "        targets = np.concatenate(targets)\n",
    "        result_metrics = calculate_metrics_multiclass(model_result, targets)\n",
    "        print(\"epoch:{:2d} iter:{:3d}\".format(epoch, iteration))\n",
    "        display(pd.DataFrame(result_metrics))\n",
    "\n",
    "\n",
    "    loss_value = np.mean(batch_losses)\n",
    "    print(\"epoch:{:2d} iter:{:3d} train: loss:{:.3f}\".format(epoch, iteration, loss_value))\n",
    "    if epoch % save_freq == 0:\n",
    "        save_path = f'checkpoints/ep_{epoch:02d}'\n",
    "        checkpoint_save(model, optimizer, save_path, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), 'strawdisease.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Strawberry.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
